{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install dcll pkgs from below\n",
    "# https://github.com/nmi-lab/dcll\n",
    "# and then enjoy yourself.\n",
    "# If there is any question please mail me.\n",
    "# CUDA_VISIBLE_DEVICES=6 python3 example_gesture_scnn.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dcll\n",
    "from dcll.load_dvsgestures_sparse import *\n",
    "import argparse, pickle, torch, time, os\n",
    "from importlib import import_module\n",
    "import torch.nn as nn\n",
    "import LIAF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "LIAF.using_syn_batchnorm = False\n",
    "torch.backends.cudnn.deterministic = True   #保证每次结果一样\n",
    "\n",
    "#TODO 1: enter ur path (for result)\n",
    "#TODO 2: put your dataset(unziped) in dcll-maseter/data\n",
    "#TODO 3: if any error plz mail me(dcll pakage has some bugs..)\n",
    "resultPath = './result_LIAF.csv'\n",
    "modelPath =  './dvs_gestrue_model'\n",
    "\n",
    "#################################\n",
    "#Arg for network\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate =3e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#################################\n",
    "#Arg for dataset\n",
    "# For how many ms do we present a sample during classification\n",
    "# How many epochs to run before testing\n",
    "n_test_interval = 20\n",
    "\n",
    "time_window = 8\n",
    "n_iters =  time_window\n",
    "n_iters_test =  time_window\n",
    "dt = 100*1000  # us, time of event accumulation for 1 frame\n",
    "ds = 4      # size scale (1/ds)\n",
    "target_size = 11 # num_classes\n",
    "n_epochs = 4000  # in fact number of batches(no classical epoch)\n",
    "in_channels = 2  # Green and Red\n",
    "im_dims = im_width, im_height = (128 // ds, 128 // ds)\n",
    "names = 'dvsGesture_stbp_cnn_test1'\n",
    "\n",
    "#################################\n",
    "\n",
    "parser = argparse.ArgumentParser(description='STBP for DVS gestures')\n",
    "loss_train_list = []\n",
    "loss_test_list = []\n",
    "acc_train_list = []\n",
    "acc_test_list = []\n",
    "train_correct = 0\n",
    "test_epoch = 20\n",
    "\n",
    "# Load data\n",
    "gen_train, _ = create_data(\n",
    "    batch_size=batch_size,\n",
    "    chunk_size=n_iters,\n",
    "    size=[in_channels, im_width, im_height],\n",
    "    ds=ds,\n",
    "    dt=dt)\n",
    "\n",
    "_, gen_test = create_data(\n",
    "    batch_size=batch_size,\n",
    "    chunk_size=n_iters_test,\n",
    "    size=[in_channels, im_width, im_height],\n",
    "    ds=ds,\n",
    "    dt=dt)\n",
    "\n",
    "def generate_data(gen_test, n_test: int, offset=0):\n",
    "    input_test, labels_test = gen_test.next(offset=offset)\n",
    "    input_tests = []\n",
    "    labels1h_tests = []\n",
    "    n_test = min(n_test, int(np.ceil(input_test.shape[0] / batch_size)))\n",
    "    for i in range(n_test):\n",
    "        input_tests.append(\n",
    "            torch.Tensor(input_test.swapaxes(0, 1))[:, i * batch_size:(i + 1) * batch_size].reshape(n_iters_test, -1,\n",
    "                                                                                                    in_channels,\n",
    "                                                                                                    im_width,\n",
    "                                                                                                    im_height))\n",
    "        labels1h_tests.append(torch.Tensor(labels_test[:, i * batch_size:(i + 1) * batch_size]))\n",
    "    return n_test, input_tests, labels1h_tests\n",
    "\n",
    "n_test, input_tests, labels1h_tests = generate_data(gen_test, n_test=300, offset=0)\n",
    "print('test_data_samples:',n_test*batch_size)\n",
    "\n",
    "modules = import_module('LIAFnet.LIAFCNN')\n",
    "config = modules.Config()\n",
    "config.cfgCnn = [(16, 64, 3, 1, 1, False),(64, 128, 3, 2, 1, True),(128, 128, 3, 2, 1, True)]\n",
    "config.cfgFc = [256, 11]\n",
    "config.decay = 0.3\n",
    "config.dropOut= 0\n",
    "config.dataSize=[im_width,im_height]\n",
    "config.padding=1\n",
    "config.timeWindows=time_window\n",
    "config.dropOut=0\n",
    "config.useBatchNorm=True\n",
    "config.useThreshFiring=True\n",
    "config.actFun=torch.selu\n",
    "snn = modules.LIAFCNN(config).to(device)\n",
    "\n",
    "best_acc = 0\n",
    "acc = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "######################################################################################\n",
    "#note:\n",
    "#CorssEntrophyLoss适用于分类问题（其为Max函数的连续近似）\n",
    "#它的输入是output（每一类别的概率）和label（第几个类别）\n",
    "######################################################################################\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=learning_rate)\n",
    "\n",
    "running_loss = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    #training\n",
    "    snn.train(mode=True)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    for i in range(1064//batch_size):\n",
    "        \n",
    "        \n",
    "        snn.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        start_time = time.time()\n",
    "        images, labels = gen_train.next()\n",
    "        images = torch.Tensor(images.swapaxes(1,2)).float()\n",
    "        labels = torch.from_numpy(labels).float()\n",
    "        _ , labels = labels[1, :, :].max(dim=1)\n",
    "        \n",
    "        \n",
    "        images = images.reshape(batch_size,16,1,32,32)\n",
    "        \n",
    "        outputs = snn(images)\n",
    "        loss = criterion(outputs.cpu(), labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        _ , predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += batch_size\n",
    "        correct +=  (predicted.cpu() == labels.cpu()).sum()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%4 == 0:\n",
    "            print('Epoch [%d,%d/%d], Loss:%.5f' % (i, epoch + 1, n_epochs, running_loss/10))\n",
    "            print('Epoch [%d,%d/%d], Acc :%.5f' % (i, epoch + 1, n_epochs, 100 * correct.float()/ total ))\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            running_loss = 0\n",
    "            \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
